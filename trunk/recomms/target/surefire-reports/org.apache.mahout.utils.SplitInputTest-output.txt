12/02/13 16:22:07 INFO utils.SplitInput: spamassasin has 4 lines
12/02/13 16:22:07 INFO utils.SplitInput: spamassasin test split size is 1
12/02/13 16:22:07 INFO utils.SplitInput: spamassasin test split start is 3 based on split location 100
12/02/13 16:22:07 INFO utils.SplitInput: file: spamassasin, input: 4 train: 3, test: 1 starting at 3
12/02/13 16:22:07 INFO utils.SplitInput: mahout has 4 lines
12/02/13 16:22:07 INFO utils.SplitInput: mahout test split size is 1
12/02/13 16:22:07 INFO utils.SplitInput: mahout test split start is 3 based on split location 100
12/02/13 16:22:07 INFO utils.SplitInput: file: mahout, input: 4 train: 3, test: 1 starting at 3
12/02/13 16:22:07 INFO utils.SplitInput: lucene has 4 lines
12/02/13 16:22:07 INFO utils.SplitInput: lucene test split size is 1
12/02/13 16:22:07 INFO utils.SplitInput: lucene test split start is 3 based on split location 100
12/02/13 16:22:07 INFO utils.SplitInput: file: lucene, input: 4 train: 3, test: 1 starting at 3
12/02/13 16:22:07 INFO utils.SplitInput: bayesinputfile has 12 lines
12/02/13 16:22:07 INFO utils.SplitInput: bayesinputfile test split size is 2
12/02/13 16:22:07 INFO utils.SplitInput: bayesinputfile test split start is 10 based on split location 100
12/02/13 16:22:07 INFO utils.SplitInput: file: bayesinputfile, input: 12 train: 10, test: 2 starting at 10
12/02/13 16:22:07 INFO utils.SplitInput: bayesinputfile has 12 lines
12/02/13 16:22:07 INFO utils.SplitInput: bayesinputfile test split size is 2
12/02/13 16:22:07 INFO utils.SplitInput: bayesinputfile test split start is 6 based on split location 50
12/02/13 16:22:07 INFO utils.SplitInput: file: bayesinputfile, input: 12 train: 10, test: 2 starting at 6
12/02/13 16:22:07 INFO utils.SplitInput: bayesinputfile has 12 lines
12/02/13 16:22:07 INFO utils.SplitInput: bayesinputfile test split size is 3 based on percentage 25
12/02/13 16:22:07 INFO utils.SplitInput: bayesinputfile test split start is 9 based on split location 100
12/02/13 16:22:07 INFO utils.SplitInput: file: bayesinputfile, input: 12 train: 9, test: 3 starting at 9
12/02/13 16:22:07 INFO utils.SplitInput: bayesinputfile has 12 lines
12/02/13 16:22:07 INFO utils.SplitInput: bayesinputfile test split size is 3 based on percentage 25
12/02/13 16:22:07 INFO utils.SplitInput: bayesinputfile test split start is 6 based on split location 50
12/02/13 16:22:07 INFO utils.SplitInput: file: bayesinputfile, input: 12 train: 9, test: 3 starting at 6
12/02/13 16:22:07 INFO utils.SplitInput: bayesinputfile has 12 lines
12/02/13 16:22:07 INFO utils.SplitInput: bayesinputfile test split size is 5 based on random selection percentage -1
12/02/13 16:22:07 INFO utils.SplitInput: file: bayesinputfile, input: 12 train: 7, test: 5 starting at 0
12/02/13 16:22:07 INFO utils.SplitInput: bayesinputfile has 12 lines
12/02/13 16:22:07 INFO utils.SplitInput: bayesinputfile test split size is 3 based on random selection percentage 25
12/02/13 16:22:07 INFO utils.SplitInput: file: bayesinputfile, input: 12 train: 9, test: 3 starting at 0
12/02/13 16:22:08 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
12/02/13 16:22:08 INFO compress.CodecPool: Got brand-new compressor
12/02/13 16:22:08 INFO compress.CodecPool: Got brand-new decompressor
12/02/13 16:22:08 WARN mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
12/02/13 16:22:08 WARN mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
12/02/13 16:22:08 INFO input.FileInputFormat: Total input paths to process : 1
12/02/13 16:22:08 INFO mapred.JobClient: Running job: job_local_0006
12/02/13 16:22:08 INFO mapred.MapTask: io.sort.mb = 100
12/02/13 16:22:08 INFO mapred.MapTask: data buffer = 79691776/99614720
12/02/13 16:22:08 INFO mapred.MapTask: record buffer = 262144/327680
12/02/13 16:22:08 INFO compress.CodecPool: Got brand-new decompressor
12/02/13 16:22:08 INFO mapred.MapTask: Starting flush of map output
12/02/13 16:22:08 INFO mapred.MapTask: Finished spill 0
12/02/13 16:22:08 INFO mapred.Task: Task:attempt_local_0006_m_000000_0 is done. And is in the process of commiting
12/02/13 16:22:09 INFO mapred.JobClient:  map 0% reduce 0%
12/02/13 16:22:11 INFO mapred.LocalJobRunner: 
12/02/13 16:22:11 INFO mapred.Task: Task 'attempt_local_0006_m_000000_0' done.
12/02/13 16:22:11 INFO mapred.LocalJobRunner: 
12/02/13 16:22:11 INFO mapred.Merger: Merging 1 sorted segments
12/02/13 16:22:11 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 1480 bytes
12/02/13 16:22:11 INFO mapred.LocalJobRunner: 
12/02/13 16:22:11 INFO mapred.Task: Task:attempt_local_0006_r_000000_0 is done. And is in the process of commiting
12/02/13 16:22:11 INFO mapred.LocalJobRunner: 
12/02/13 16:22:11 INFO mapred.Task: Task attempt_local_0006_r_000000_0 is allowed to commit now
12/02/13 16:22:11 INFO output.FileOutputCommitter: Saved output of task 'attempt_local_0006_r_000000_0' to file:/tmp/mahout-SplitInputTest-6975384134592428032/mapRedOutput
12/02/13 16:22:12 INFO mapred.JobClient:  map 100% reduce 0%
12/02/13 16:22:14 INFO mapred.LocalJobRunner: reduce > reduce
12/02/13 16:22:14 INFO mapred.Task: Task 'attempt_local_0006_r_000000_0' done.
12/02/13 16:22:15 INFO mapred.JobClient:  map 100% reduce 100%
12/02/13 16:22:15 INFO mapred.JobClient: Job complete: job_local_0006
12/02/13 16:22:15 INFO mapred.JobClient: Counters: 16
12/02/13 16:22:15 INFO mapred.JobClient:   File Output Format Counters 
12/02/13 16:22:15 INFO mapred.JobClient:     Bytes Written=90
12/02/13 16:22:15 INFO mapred.JobClient:   FileSystemCounters
12/02/13 16:22:15 INFO mapred.JobClient:     FILE_BYTES_READ=54839544
12/02/13 16:22:15 INFO mapred.JobClient:     FILE_BYTES_WRITTEN=41960126
12/02/13 16:22:15 INFO mapred.JobClient:   File Input Format Counters 
12/02/13 16:22:15 INFO mapred.JobClient:     Bytes Read=29417
12/02/13 16:22:15 INFO mapred.JobClient:   Map-Reduce Framework
12/02/13 16:22:15 INFO mapred.JobClient:     Reduce input groups=100
12/02/13 16:22:15 INFO mapred.JobClient:     Map output materialized bytes=1484
12/02/13 16:22:15 INFO mapred.JobClient:     Combine output records=0
12/02/13 16:22:15 INFO mapred.JobClient:     Map input records=1000
12/02/13 16:22:15 INFO mapred.JobClient:     Reduce shuffle bytes=0
12/02/13 16:22:15 INFO mapred.JobClient:     Reduce output records=0
12/02/13 16:22:15 INFO mapred.JobClient:     Spilled Records=200
12/02/13 16:22:15 INFO mapred.JobClient:     Map output bytes=1278
12/02/13 16:22:15 INFO mapred.JobClient:     Combine input records=0
12/02/13 16:22:15 INFO mapred.JobClient:     Map output records=100
12/02/13 16:22:15 INFO mapred.JobClient:     SPLIT_RAW_BYTES=139
12/02/13 16:22:15 INFO mapred.JobClient:     Reduce input records=100
Test data: 25 records
730	Line 730
790	Line 790
340	Line 340
30	Line 30
430	Line 430
200	Line 200
400	Line 400
410	Line 410
180	Line 180
780	Line 780
870	Line 870
920	Line 920
970	Line 970
300	Line 300
480	Line 480
290	Line 290
890	Line 890
120	Line 120
170	Line 170
910	Line 910
140	Line 140
530	Line 530
190	Line 190
900	Line 900
620	Line 620
Training data: 75 records
270	Line 270
850	Line 850
220	Line 220
540	Line 540
550	Line 550
880	Line 880
70	Line 70
940	Line 940
680	Line 680
320	Line 320
310	Line 310
960	Line 960
580	Line 580
590	Line 590
50	Line 50
360	Line 360
690	Line 690
740	Line 740
510	Line 510
0	Line 0
560	Line 560
520	Line 520
820	Line 820
40	Line 40
570	Line 570
240	Line 240
640	Line 640
130	Line 130
650	Line 650
660	Line 660
500	Line 500
670	Line 670
630	Line 630
800	Line 800
250	Line 250
20	Line 20
260	Line 260
100	Line 100
760	Line 760
380	Line 380
10	Line 10
980	Line 980
470	Line 470
600	Line 600
930	Line 930
420	Line 420
80	Line 80
110	Line 110
160	Line 160
90	Line 90
280	Line 280
330	Line 330
720	Line 720
460	Line 460
750	Line 750
950	Line 950
830	Line 830
210	Line 210
710	Line 710
810	Line 810
390	Line 390
150	Line 150
60	Line 60
700	Line 700
230	Line 230
350	Line 350
610	Line 610
840	Line 840
770	Line 770
370	Line 370
440	Line 440
490	Line 490
450	Line 450
860	Line 860
990	Line 990
12/02/13 16:22:15 INFO common.AbstractJob: Command line arguments: {--endPhase=2147483647, --input=file:/tmp/mahout-SplitInputTest-5598620771545646080/tmpsequence, --keepPct=10, --mapRedOutputDir=file:/tmp/mahout-SplitInputTest-5598620771545646080/mapRedOutput, --method=mapreduce, --overwrite=null, --randomSelectionPct=25, --startPhase=0, --tempDir=temp}
12/02/13 16:22:15 WARN mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
12/02/13 16:22:15 WARN mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
12/02/13 16:22:15 INFO input.FileInputFormat: Total input paths to process : 1
12/02/13 16:22:15 INFO mapred.JobClient: Running job: job_local_0007
12/02/13 16:22:15 INFO mapred.MapTask: io.sort.mb = 100
12/02/13 16:22:15 INFO mapred.MapTask: data buffer = 79691776/99614720
12/02/13 16:22:15 INFO mapred.MapTask: record buffer = 262144/327680
12/02/13 16:22:15 INFO compress.CodecPool: Got brand-new decompressor
12/02/13 16:22:15 INFO mapred.MapTask: Starting flush of map output
12/02/13 16:22:15 INFO mapred.MapTask: Finished spill 0
12/02/13 16:22:15 INFO mapred.Task: Task:attempt_local_0007_m_000000_0 is done. And is in the process of commiting
12/02/13 16:22:16 INFO mapred.JobClient:  map 0% reduce 0%
12/02/13 16:22:18 INFO mapred.LocalJobRunner: 
12/02/13 16:22:18 INFO mapred.Task: Task 'attempt_local_0007_m_000000_0' done.
12/02/13 16:22:18 INFO mapred.JobClient:  map 100% reduce 0%
12/02/13 16:22:18 INFO mapred.LocalJobRunner: 
12/02/13 16:22:18 INFO mapred.Merger: Merging 1 sorted segments
12/02/13 16:22:18 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 1480 bytes
12/02/13 16:22:18 INFO mapred.LocalJobRunner: 
12/02/13 16:22:18 INFO mapred.Task: Task:attempt_local_0007_r_000000_0 is done. And is in the process of commiting
12/02/13 16:22:18 INFO mapred.LocalJobRunner: 
12/02/13 16:22:18 INFO mapred.Task: Task attempt_local_0007_r_000000_0 is allowed to commit now
12/02/13 16:22:18 INFO output.FileOutputCommitter: Saved output of task 'attempt_local_0007_r_000000_0' to file:/tmp/mahout-SplitInputTest-5598620771545646080/mapRedOutput
12/02/13 16:22:21 INFO mapred.LocalJobRunner: reduce > reduce
12/02/13 16:22:21 INFO mapred.Task: Task 'attempt_local_0007_r_000000_0' done.
12/02/13 16:22:22 INFO mapred.JobClient:  map 100% reduce 100%
12/02/13 16:22:22 INFO mapred.JobClient: Job complete: job_local_0007
12/02/13 16:22:22 INFO mapred.JobClient: Counters: 16
12/02/13 16:22:22 INFO mapred.JobClient:   File Output Format Counters 
12/02/13 16:22:22 INFO mapred.JobClient:     Bytes Written=90
12/02/13 16:22:22 INFO mapred.JobClient:   FileSystemCounters
12/02/13 16:22:22 INFO mapred.JobClient:     FILE_BYTES_READ=54919496
12/02/13 16:22:22 INFO mapred.JobClient:     FILE_BYTES_WRITTEN=42094448
12/02/13 16:22:22 INFO mapred.JobClient:   File Input Format Counters 
12/02/13 16:22:22 INFO mapred.JobClient:     Bytes Read=29417
12/02/13 16:22:22 INFO mapred.JobClient:   Map-Reduce Framework
12/02/13 16:22:22 INFO mapred.JobClient:     Reduce input groups=100
12/02/13 16:22:22 INFO mapred.JobClient:     Map output materialized bytes=1484
12/02/13 16:22:22 INFO mapred.JobClient:     Combine output records=0
12/02/13 16:22:22 INFO mapred.JobClient:     Map input records=1000
12/02/13 16:22:22 INFO mapred.JobClient:     Reduce shuffle bytes=0
12/02/13 16:22:22 INFO mapred.JobClient:     Reduce output records=0
12/02/13 16:22:22 INFO mapred.JobClient:     Spilled Records=200
12/02/13 16:22:22 INFO mapred.JobClient:     Map output bytes=1278
12/02/13 16:22:22 INFO mapred.JobClient:     Combine input records=0
12/02/13 16:22:22 INFO mapred.JobClient:     Map output records=100
12/02/13 16:22:22 INFO mapred.JobClient:     SPLIT_RAW_BYTES=139
12/02/13 16:22:22 INFO mapred.JobClient:     Reduce input records=100
Test data: 25 records
730	Line 730
790	Line 790
340	Line 340
30	Line 30
430	Line 430
200	Line 200
400	Line 400
410	Line 410
180	Line 180
780	Line 780
870	Line 870
920	Line 920
970	Line 970
300	Line 300
480	Line 480
290	Line 290
890	Line 890
120	Line 120
170	Line 170
910	Line 910
140	Line 140
530	Line 530
190	Line 190
900	Line 900
620	Line 620
Training data: 75 records
270	Line 270
850	Line 850
220	Line 220
540	Line 540
550	Line 550
880	Line 880
70	Line 70
940	Line 940
680	Line 680
320	Line 320
310	Line 310
960	Line 960
580	Line 580
590	Line 590
50	Line 50
360	Line 360
690	Line 690
740	Line 740
510	Line 510
0	Line 0
560	Line 560
520	Line 520
820	Line 820
40	Line 40
570	Line 570
240	Line 240
640	Line 640
130	Line 130
650	Line 650
660	Line 660
500	Line 500
670	Line 670
630	Line 630
800	Line 800
250	Line 250
20	Line 20
260	Line 260
100	Line 100
760	Line 760
380	Line 380
10	Line 10
980	Line 980
470	Line 470
600	Line 600
930	Line 930
420	Line 420
80	Line 80
110	Line 110
160	Line 160
90	Line 90
280	Line 280
330	Line 330
720	Line 720
460	Line 460
750	Line 750
950	Line 950
830	Line 830
210	Line 210
710	Line 710
810	Line 810
390	Line 390
150	Line 150
60	Line 60
700	Line 700
230	Line 230
350	Line 350
610	Line 610
840	Line 840
770	Line 770
370	Line 370
440	Line 440
490	Line 490
450	Line 450
860	Line 860
990	Line 990
12/02/13 16:22:22 WARN mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
12/02/13 16:22:22 WARN mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
12/02/13 16:22:22 INFO input.FileInputFormat: Total input paths to process : 1
12/02/13 16:22:22 INFO mapred.JobClient: Running job: job_local_0008
12/02/13 16:22:22 INFO mapred.MapTask: io.sort.mb = 100
12/02/13 16:22:22 INFO mapred.MapTask: data buffer = 79691776/99614720
12/02/13 16:22:22 INFO mapred.MapTask: record buffer = 262144/327680
12/02/13 16:22:22 INFO compress.CodecPool: Got brand-new decompressor
12/02/13 16:22:22 INFO mapred.MapTask: Starting flush of map output
12/02/13 16:22:22 INFO mapred.MapTask: Finished spill 0
12/02/13 16:22:22 INFO mapred.Task: Task:attempt_local_0008_m_000000_0 is done. And is in the process of commiting
12/02/13 16:22:23 INFO mapred.JobClient:  map 0% reduce 0%
12/02/13 16:22:25 INFO mapred.LocalJobRunner: 
12/02/13 16:22:25 INFO mapred.Task: Task 'attempt_local_0008_m_000000_0' done.
12/02/13 16:22:25 INFO mapred.LocalJobRunner: 
12/02/13 16:22:25 INFO mapred.Merger: Merging 1 sorted segments
12/02/13 16:22:25 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 4466 bytes
12/02/13 16:22:25 INFO mapred.LocalJobRunner: 
12/02/13 16:22:25 INFO mapred.Task: Task:attempt_local_0008_r_000000_0 is done. And is in the process of commiting
12/02/13 16:22:25 INFO mapred.LocalJobRunner: 
12/02/13 16:22:25 INFO mapred.Task: Task attempt_local_0008_r_000000_0 is allowed to commit now
12/02/13 16:22:25 INFO output.FileOutputCommitter: Saved output of task 'attempt_local_0008_r_000000_0' to file:/tmp/mahout-SplitInputTest-8335373819155269632/mapRedOutput
12/02/13 16:22:26 INFO mapred.JobClient:  map 100% reduce 0%
12/02/13 16:22:28 INFO mapred.LocalJobRunner: reduce > reduce
12/02/13 16:22:28 INFO mapred.Task: Task 'attempt_local_0008_r_000000_0' done.
12/02/13 16:22:29 INFO mapred.JobClient:  map 100% reduce 100%
12/02/13 16:22:29 INFO mapred.JobClient: Job complete: job_local_0008
12/02/13 16:22:29 INFO mapred.JobClient: Counters: 16
12/02/13 16:22:29 INFO mapred.JobClient:   File Output Format Counters 
12/02/13 16:22:29 INFO mapred.JobClient:     Bytes Written=109
12/02/13 16:22:29 INFO mapred.JobClient:   FileSystemCounters
12/02/13 16:22:29 INFO mapred.JobClient:     FILE_BYTES_READ=55008822
12/02/13 16:22:29 INFO mapred.JobClient:     FILE_BYTES_WRITTEN=42244389
12/02/13 16:22:29 INFO mapred.JobClient:   File Input Format Counters 
12/02/13 16:22:29 INFO mapred.JobClient:     Bytes Read=32583
12/02/13 16:22:29 INFO mapred.JobClient:   Map-Reduce Framework
12/02/13 16:22:29 INFO mapred.JobClient:     Reduce input groups=100
12/02/13 16:22:29 INFO mapred.JobClient:     Map output materialized bytes=4470
12/02/13 16:22:29 INFO mapred.JobClient:     Combine output records=0
12/02/13 16:22:29 INFO mapred.JobClient:     Map input records=1000
12/02/13 16:22:29 INFO mapred.JobClient:     Reduce shuffle bytes=0
12/02/13 16:22:29 INFO mapred.JobClient:     Reduce output records=0
12/02/13 16:22:29 INFO mapred.JobClient:     Spilled Records=200
12/02/13 16:22:29 INFO mapred.JobClient:     Map output bytes=4264
12/02/13 16:22:29 INFO mapred.JobClient:     Combine input records=0
12/02/13 16:22:29 INFO mapred.JobClient:     Map output records=100
12/02/13 16:22:29 INFO mapred.JobClient:     SPLIT_RAW_BYTES=139
12/02/13 16:22:29 INFO mapred.JobClient:     Reduce input records=100
Test data: 25 records
730	{0:730.0,1:730.0,2:730.0,3:730.0}
790	{0:790.0,1:790.0,2:790.0,3:790.0}
340	{0:340.0,1:340.0,2:340.0,3:340.0}
30	{0:30.0,1:30.0,2:30.0,3:30.0}
430	{0:430.0,1:430.0,2:430.0,3:430.0}
200	{0:200.0,1:200.0,2:200.0,3:200.0}
400	{0:400.0,1:400.0,2:400.0,3:400.0}
410	{0:410.0,1:410.0,2:410.0,3:410.0}
180	{0:180.0,1:180.0,2:180.0,3:180.0}
780	{0:780.0,1:780.0,2:780.0,3:780.0}
870	{0:870.0,1:870.0,2:870.0,3:870.0}
920	{0:920.0,1:920.0,2:920.0,3:920.0}
970	{0:970.0,1:970.0,2:970.0,3:970.0}
300	{0:300.0,1:300.0,2:300.0,3:300.0}
480	{0:480.0,1:480.0,2:480.0,3:480.0}
290	{0:290.0,1:290.0,2:290.0,3:290.0}
890	{0:890.0,1:890.0,2:890.0,3:890.0}
120	{0:120.0,1:120.0,2:120.0,3:120.0}
170	{0:170.0,1:170.0,2:170.0,3:170.0}
910	{0:910.0,1:910.0,2:910.0,3:910.0}
140	{0:140.0,1:140.0,2:140.0,3:140.0}
530	{0:530.0,1:530.0,2:530.0,3:530.0}
190	{0:190.0,1:190.0,2:190.0,3:190.0}
900	{0:900.0,1:900.0,2:900.0,3:900.0}
620	{0:620.0,1:620.0,2:620.0,3:620.0}
Training data: 75 records
270	{0:270.0,1:270.0,2:270.0,3:270.0}
850	{0:850.0,1:850.0,2:850.0,3:850.0}
220	{0:220.0,1:220.0,2:220.0,3:220.0}
540	{0:540.0,1:540.0,2:540.0,3:540.0}
550	{0:550.0,1:550.0,2:550.0,3:550.0}
880	{0:880.0,1:880.0,2:880.0,3:880.0}
70	{0:70.0,1:70.0,2:70.0,3:70.0}
940	{0:940.0,1:940.0,2:940.0,3:940.0}
680	{0:680.0,1:680.0,2:680.0,3:680.0}
320	{0:320.0,1:320.0,2:320.0,3:320.0}
310	{0:310.0,1:310.0,2:310.0,3:310.0}
960	{0:960.0,1:960.0,2:960.0,3:960.0}
580	{0:580.0,1:580.0,2:580.0,3:580.0}
590	{0:590.0,1:590.0,2:590.0,3:590.0}
50	{0:50.0,1:50.0,2:50.0,3:50.0}
360	{0:360.0,1:360.0,2:360.0,3:360.0}
690	{0:690.0,1:690.0,2:690.0,3:690.0}
740	{0:740.0,1:740.0,2:740.0,3:740.0}
510	{0:510.0,1:510.0,2:510.0,3:510.0}
0	{
560	{0:560.0,1:560.0,2:560.0,3:560.0}
520	{0:520.0,1:520.0,2:520.0,3:520.0}
820	{0:820.0,1:820.0,2:820.0,3:820.0}
40	{0:40.0,1:40.0,2:40.0,3:40.0}
570	{0:570.0,1:570.0,2:570.0,3:570.0}
240	{0:240.0,1:240.0,2:240.0,3:240.0}
640	{0:640.0,1:640.0,2:640.0,3:640.0}
130	{0:130.0,1:130.0,2:130.0,3:130.0}
650	{0:650.0,1:650.0,2:650.0,3:650.0}
660	{0:660.0,1:660.0,2:660.0,3:660.0}
500	{0:500.0,1:500.0,2:500.0,3:500.0}
670	{0:670.0,1:670.0,2:670.0,3:670.0}
630	{0:630.0,1:630.0,2:630.0,3:630.0}
800	{0:800.0,1:800.0,2:800.0,3:800.0}
250	{0:250.0,1:250.0,2:250.0,3:250.0}
20	{0:20.0,1:20.0,2:20.0,3:20.0}
260	{0:260.0,1:260.0,2:260.0,3:260.0}
100	{0:100.0,1:100.0,2:100.0,3:100.0}
760	{0:760.0,1:760.0,2:760.0,3:760.0}
380	{0:380.0,1:380.0,2:380.0,3:380.0}
10	{0:10.0,1:10.0,2:10.0,3:10.0}
980	{0:980.0,1:980.0,2:980.0,3:980.0}
470	{0:470.0,1:470.0,2:470.0,3:470.0}
600	{0:600.0,1:600.0,2:600.0,3:600.0}
930	{0:930.0,1:930.0,2:930.0,3:930.0}
420	{0:420.0,1:420.0,2:420.0,3:420.0}
80	{0:80.0,1:80.0,2:80.0,3:80.0}
110	{0:110.0,1:110.0,2:110.0,3:110.0}
160	{0:160.0,1:160.0,2:160.0,3:160.0}
90	{0:90.0,1:90.0,2:90.0,3:90.0}
280	{0:280.0,1:280.0,2:280.0,3:280.0}
330	{0:330.0,1:330.0,2:330.0,3:330.0}
720	{0:720.0,1:720.0,2:720.0,3:720.0}
460	{0:460.0,1:460.0,2:460.0,3:460.0}
750	{0:750.0,1:750.0,2:750.0,3:750.0}
950	{0:950.0,1:950.0,2:950.0,3:950.0}
830	{0:830.0,1:830.0,2:830.0,3:830.0}
210	{0:210.0,1:210.0,2:210.0,3:210.0}
710	{0:710.0,1:710.0,2:710.0,3:710.0}
810	{0:810.0,1:810.0,2:810.0,3:810.0}
390	{0:390.0,1:390.0,2:390.0,3:390.0}
150	{0:150.0,1:150.0,2:150.0,3:150.0}
60	{0:60.0,1:60.0,2:60.0,3:60.0}
700	{0:700.0,1:700.0,2:700.0,3:700.0}
230	{0:230.0,1:230.0,2:230.0,3:230.0}
350	{0:350.0,1:350.0,2:350.0,3:350.0}
610	{0:610.0,1:610.0,2:610.0,3:610.0}
840	{0:840.0,1:840.0,2:840.0,3:840.0}
770	{0:770.0,1:770.0,2:770.0,3:770.0}
370	{0:370.0,1:370.0,2:370.0,3:370.0}
440	{0:440.0,1:440.0,2:440.0,3:440.0}
490	{0:490.0,1:490.0,2:490.0,3:490.0}
450	{0:450.0,1:450.0,2:450.0,3:450.0}
860	{0:860.0,1:860.0,2:860.0,3:860.0}
990	{0:990.0,1:990.0,2:990.0,3:990.0}
12/02/13 16:22:29 INFO common.AbstractJob: Command line arguments: {--endPhase=2147483647, --input=file:/tmp/mahout-SplitInputTest-6777004751292619776/tmpsequence, --keepPct=10, --mapRedOutputDir=file:/tmp/mahout-SplitInputTest-6777004751292619776/mapRedOutput, --method=mapreduce, --overwrite=null, --randomSelectionPct=25, --startPhase=0, --tempDir=temp}
12/02/13 16:22:29 WARN mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
12/02/13 16:22:29 WARN mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
12/02/13 16:22:29 INFO input.FileInputFormat: Total input paths to process : 1
12/02/13 16:22:29 INFO mapred.JobClient: Running job: job_local_0009
12/02/13 16:22:29 INFO mapred.MapTask: io.sort.mb = 100
12/02/13 16:22:29 INFO mapred.MapTask: data buffer = 79691776/99614720
12/02/13 16:22:29 INFO mapred.MapTask: record buffer = 262144/327680
12/02/13 16:22:29 INFO compress.CodecPool: Got brand-new decompressor
12/02/13 16:22:29 INFO mapred.MapTask: Starting flush of map output
12/02/13 16:22:29 INFO mapred.MapTask: Finished spill 0
12/02/13 16:22:29 INFO mapred.Task: Task:attempt_local_0009_m_000000_0 is done. And is in the process of commiting
12/02/13 16:22:30 INFO mapred.JobClient:  map 0% reduce 0%
12/02/13 16:22:32 INFO mapred.LocalJobRunner: 
12/02/13 16:22:32 INFO mapred.Task: Task 'attempt_local_0009_m_000000_0' done.
12/02/13 16:22:32 INFO mapred.LocalJobRunner: 
12/02/13 16:22:32 INFO mapred.Merger: Merging 1 sorted segments
12/02/13 16:22:32 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 4466 bytes
12/02/13 16:22:32 INFO mapred.LocalJobRunner: 
12/02/13 16:22:32 INFO mapred.Task: Task:attempt_local_0009_r_000000_0 is done. And is in the process of commiting
12/02/13 16:22:32 INFO mapred.LocalJobRunner: 
12/02/13 16:22:32 INFO mapred.Task: Task attempt_local_0009_r_000000_0 is allowed to commit now
12/02/13 16:22:32 INFO output.FileOutputCommitter: Saved output of task 'attempt_local_0009_r_000000_0' to file:/tmp/mahout-SplitInputTest-6777004751292619776/mapRedOutput
12/02/13 16:22:33 INFO mapred.JobClient:  map 100% reduce 0%
12/02/13 16:22:35 INFO mapred.LocalJobRunner: reduce > reduce
12/02/13 16:22:35 INFO mapred.Task: Task 'attempt_local_0009_r_000000_0' done.
12/02/13 16:22:36 INFO mapred.JobClient:  map 100% reduce 100%
12/02/13 16:22:36 INFO mapred.JobClient: Job complete: job_local_0009
12/02/13 16:22:36 INFO mapred.JobClient: Counters: 16
12/02/13 16:22:36 INFO mapred.JobClient:   File Output Format Counters 
12/02/13 16:22:36 INFO mapred.JobClient:     Bytes Written=109
12/02/13 16:22:36 INFO mapred.JobClient:   FileSystemCounters
12/02/13 16:22:36 INFO mapred.JobClient:     FILE_BYTES_READ=55113390
12/02/13 16:22:36 INFO mapred.JobClient:     FILE_BYTES_WRITTEN=42397417
12/02/13 16:22:36 INFO mapred.JobClient:   File Input Format Counters 
12/02/13 16:22:36 INFO mapred.JobClient:     Bytes Read=32583
12/02/13 16:22:36 INFO mapred.JobClient:   Map-Reduce Framework
12/02/13 16:22:36 INFO mapred.JobClient:     Reduce input groups=100
12/02/13 16:22:36 INFO mapred.JobClient:     Map output materialized bytes=4470
12/02/13 16:22:36 INFO mapred.JobClient:     Combine output records=0
12/02/13 16:22:36 INFO mapred.JobClient:     Map input records=1000
12/02/13 16:22:36 INFO mapred.JobClient:     Reduce shuffle bytes=0
12/02/13 16:22:36 INFO mapred.JobClient:     Reduce output records=0
12/02/13 16:22:36 INFO mapred.JobClient:     Spilled Records=200
12/02/13 16:22:36 INFO mapred.JobClient:     Map output bytes=4264
12/02/13 16:22:36 INFO mapred.JobClient:     Combine input records=0
12/02/13 16:22:36 INFO mapred.JobClient:     Map output records=100
12/02/13 16:22:36 INFO mapred.JobClient:     SPLIT_RAW_BYTES=139
12/02/13 16:22:36 INFO mapred.JobClient:     Reduce input records=100
Test data: 25 records
730	{0:730.0,1:730.0,2:730.0,3:730.0}
790	{0:790.0,1:790.0,2:790.0,3:790.0}
340	{0:340.0,1:340.0,2:340.0,3:340.0}
30	{0:30.0,1:30.0,2:30.0,3:30.0}
430	{0:430.0,1:430.0,2:430.0,3:430.0}
200	{0:200.0,1:200.0,2:200.0,3:200.0}
400	{0:400.0,1:400.0,2:400.0,3:400.0}
410	{0:410.0,1:410.0,2:410.0,3:410.0}
180	{0:180.0,1:180.0,2:180.0,3:180.0}
780	{0:780.0,1:780.0,2:780.0,3:780.0}
870	{0:870.0,1:870.0,2:870.0,3:870.0}
920	{0:920.0,1:920.0,2:920.0,3:920.0}
970	{0:970.0,1:970.0,2:970.0,3:970.0}
300	{0:300.0,1:300.0,2:300.0,3:300.0}
480	{0:480.0,1:480.0,2:480.0,3:480.0}
290	{0:290.0,1:290.0,2:290.0,3:290.0}
890	{0:890.0,1:890.0,2:890.0,3:890.0}
120	{0:120.0,1:120.0,2:120.0,3:120.0}
170	{0:170.0,1:170.0,2:170.0,3:170.0}
910	{0:910.0,1:910.0,2:910.0,3:910.0}
140	{0:140.0,1:140.0,2:140.0,3:140.0}
530	{0:530.0,1:530.0,2:530.0,3:530.0}
190	{0:190.0,1:190.0,2:190.0,3:190.0}
900	{0:900.0,1:900.0,2:900.0,3:900.0}
620	{0:620.0,1:620.0,2:620.0,3:620.0}
Training data: 75 records
270	{0:270.0,1:270.0,2:270.0,3:270.0}
850	{0:850.0,1:850.0,2:850.0,3:850.0}
220	{0:220.0,1:220.0,2:220.0,3:220.0}
540	{0:540.0,1:540.0,2:540.0,3:540.0}
550	{0:550.0,1:550.0,2:550.0,3:550.0}
880	{0:880.0,1:880.0,2:880.0,3:880.0}
70	{0:70.0,1:70.0,2:70.0,3:70.0}
940	{0:940.0,1:940.0,2:940.0,3:940.0}
680	{0:680.0,1:680.0,2:680.0,3:680.0}
320	{0:320.0,1:320.0,2:320.0,3:320.0}
310	{0:310.0,1:310.0,2:310.0,3:310.0}
960	{0:960.0,1:960.0,2:960.0,3:960.0}
580	{0:580.0,1:580.0,2:580.0,3:580.0}
590	{0:590.0,1:590.0,2:590.0,3:590.0}
50	{0:50.0,1:50.0,2:50.0,3:50.0}
360	{0:360.0,1:360.0,2:360.0,3:360.0}
690	{0:690.0,1:690.0,2:690.0,3:690.0}
740	{0:740.0,1:740.0,2:740.0,3:740.0}
510	{0:510.0,1:510.0,2:510.0,3:510.0}
0	{
560	{0:560.0,1:560.0,2:560.0,3:560.0}
520	{0:520.0,1:520.0,2:520.0,3:520.0}
820	{0:820.0,1:820.0,2:820.0,3:820.0}
40	{0:40.0,1:40.0,2:40.0,3:40.0}
570	{0:570.0,1:570.0,2:570.0,3:570.0}
240	{0:240.0,1:240.0,2:240.0,3:240.0}
640	{0:640.0,1:640.0,2:640.0,3:640.0}
130	{0:130.0,1:130.0,2:130.0,3:130.0}
650	{0:650.0,1:650.0,2:650.0,3:650.0}
660	{0:660.0,1:660.0,2:660.0,3:660.0}
500	{0:500.0,1:500.0,2:500.0,3:500.0}
670	{0:670.0,1:670.0,2:670.0,3:670.0}
630	{0:630.0,1:630.0,2:630.0,3:630.0}
800	{0:800.0,1:800.0,2:800.0,3:800.0}
250	{0:250.0,1:250.0,2:250.0,3:250.0}
20	{0:20.0,1:20.0,2:20.0,3:20.0}
260	{0:260.0,1:260.0,2:260.0,3:260.0}
100	{0:100.0,1:100.0,2:100.0,3:100.0}
760	{0:760.0,1:760.0,2:760.0,3:760.0}
380	{0:380.0,1:380.0,2:380.0,3:380.0}
10	{0:10.0,1:10.0,2:10.0,3:10.0}
980	{0:980.0,1:980.0,2:980.0,3:980.0}
470	{0:470.0,1:470.0,2:470.0,3:470.0}
600	{0:600.0,1:600.0,2:600.0,3:600.0}
930	{0:930.0,1:930.0,2:930.0,3:930.0}
420	{0:420.0,1:420.0,2:420.0,3:420.0}
80	{0:80.0,1:80.0,2:80.0,3:80.0}
110	{0:110.0,1:110.0,2:110.0,3:110.0}
160	{0:160.0,1:160.0,2:160.0,3:160.0}
90	{0:90.0,1:90.0,2:90.0,3:90.0}
280	{0:280.0,1:280.0,2:280.0,3:280.0}
330	{0:330.0,1:330.0,2:330.0,3:330.0}
720	{0:720.0,1:720.0,2:720.0,3:720.0}
460	{0:460.0,1:460.0,2:460.0,3:460.0}
750	{0:750.0,1:750.0,2:750.0,3:750.0}
950	{0:950.0,1:950.0,2:950.0,3:950.0}
830	{0:830.0,1:830.0,2:830.0,3:830.0}
210	{0:210.0,1:210.0,2:210.0,3:210.0}
710	{0:710.0,1:710.0,2:710.0,3:710.0}
810	{0:810.0,1:810.0,2:810.0,3:810.0}
390	{0:390.0,1:390.0,2:390.0,3:390.0}
150	{0:150.0,1:150.0,2:150.0,3:150.0}
60	{0:60.0,1:60.0,2:60.0,3:60.0}
700	{0:700.0,1:700.0,2:700.0,3:700.0}
230	{0:230.0,1:230.0,2:230.0,3:230.0}
350	{0:350.0,1:350.0,2:350.0,3:350.0}
610	{0:610.0,1:610.0,2:610.0,3:610.0}
840	{0:840.0,1:840.0,2:840.0,3:840.0}
770	{0:770.0,1:770.0,2:770.0,3:770.0}
370	{0:370.0,1:370.0,2:370.0,3:370.0}
440	{0:440.0,1:440.0,2:440.0,3:440.0}
490	{0:490.0,1:490.0,2:490.0,3:490.0}
450	{0:450.0,1:450.0,2:450.0,3:450.0}
860	{0:860.0,1:860.0,2:860.0,3:860.0}
990	{0:990.0,1:990.0,2:990.0,3:990.0}
